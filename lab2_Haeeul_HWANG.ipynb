{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ad_train = pd.read_csv('eacl2017/adjectives.train', sep='\\t', header=None)  # 5562\n",
    "ad_test = pd.read_csv('eacl2017/adjectives.test', sep='\\t', header=None)    # 1986\n",
    "ad_val = pd.read_csv('eacl2017/adjectives.val', sep='\\t', header=None)      # 398\n",
    "\n",
    "noun_train = pd.read_csv('eacl2017/nouns.train', sep='\\t', header=None) # 2836\n",
    "noun_test = pd.read_csv('eacl2017/nouns.test', sep='\\t', header=None)   # 1020\n",
    "noun_val = pd.read_csv('eacl2017/nouns.val', sep='\\t', header=None)     # 206\n",
    "\n",
    "verb_train = pd.read_csv('eacl2017/verbs.train', sep='\\t', header=None) # 2534\n",
    "verb_test = pd.read_csv('eacl2017/verbs.test', sep='\\t', header=None)   # 908\n",
    "verb_val = pd.read_csv('eacl2017/verbs.val', sep='\\t', header=None)     # 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dataset\n",
    "\n",
    "ad = pd.concat([ad_train, ad_test, ad_val])\n",
    "noun = pd.concat([noun_train, noun_test, noun_val])\n",
    "verb = pd.concat([verb_train, verb_test, verb_val])\n",
    "\n",
    "# rearrage the index\n",
    "\n",
    "ad = ad.reset_index(drop=True)\n",
    "noun = noun.reset_index(drop=True)\n",
    "verb = verb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ad_train, ad_test, ad_val, noun_train, noun_test, noun_val, verb_train, verb_test, verb_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "\n",
    "print(ad.isnull().values.any())\n",
    "print(noun.isnull().values.any())\n",
    "print(verb.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0      1  2\n",
      "9         NaN  valid  1\n",
      "308       NaN   void  0\n",
      "6171  invalid    NaN  0\n",
      "6213      NaN  empty  0\n",
      "              0    1  2\n",
      "39  grandmother  NaN  0\n"
     ]
    }
   ],
   "source": [
    "# find null values\n",
    "\n",
    "print(ad.iloc[ad[ad.isnull().any(axis=1)].index])\n",
    "print(noun.iloc[noun[noun.isnull().any(axis=1)].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values\n",
    "\n",
    "ad = ad.fillna('null')\n",
    "noun = noun.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the word2vec model\n",
    "\n",
    "import gensim\n",
    "\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distance between the words\n",
    "\n",
    "def get_distance(data):\n",
    "    distance = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            distance.append(word2vec_model.distance(data[0][i], data[1][i]))\n",
    "        except:\n",
    "            distance.append(0.5)\n",
    "    data['distance'] = distance\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I append 0.5 if there is a word that is not in the vocabulary of the word2vec model.\n",
    "0.5 seems to be a neutral value, so I think it's a good idea to use it as a default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the distance to the dataset\n",
    "\n",
    "ad = get_distance(ad)\n",
    "noun = get_distance(noun)\n",
    "verb = get_distance(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the dataset into synonyms and antonyms\n",
    "\n",
    "ad_syn = ad[ad[2] == 0]\n",
    "ad_ant = ad[ad[2] == 1]\n",
    "\n",
    "noun_syn = noun[noun[2] == 0]\n",
    "noun_ant = noun[noun[2] == 1]\n",
    "\n",
    "verb_syn = verb[verb[2] == 0]\n",
    "verb_ant = verb[verb[2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vocabulary\n",
    "\n",
    "ad_vocab = pd.concat([ad[0], ad[1]]).unique()\n",
    "noun_vocab = pd.concat([noun[0], noun[1]]).unique()\n",
    "verb_vocab = pd.concat([verb[0], verb[1]]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the distances between synonyms and antonyms, I took the vocabularies for 3 categories: \"adjective\", \"verb\", and \"noun\",\n",
    "and I calculate the average distance between d(word, synonym) and d(word, antonym) for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjectives: 15.499606608969316 \n",
      "\n",
      "nouns: 1.9269102990033222 \n",
      "\n",
      "verbs: 8.421537045559136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the % of times that d(word, synonym) < d(word, antonym)\n",
    "\n",
    "def compare_distance(syn, ant, vocab):\n",
    "    count = 0\n",
    "    for word in vocab:\n",
    "        synonyms = syn.loc[syn[0] == word]\n",
    "        antonyms = ant.loc[ant[0] == word]\n",
    "        if synonyms.empty or antonyms.empty:\n",
    "            pass\n",
    "        else:\n",
    "            if synonyms['distance'].mean() < antonyms['distance'].mean():\n",
    "                count += 1\n",
    "    return count / len(vocab) * 100\n",
    "            \n",
    "print('adjectives:', compare_distance(ad_syn, ad_ant, ad_vocab), \"\\n\")\n",
    "print('nouns:', compare_distance(noun_syn, noun_ant, noun_vocab), \"\\n\")\n",
    "print('verbs:', compare_distance(verb_syn, verb_ant, verb_vocab), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average distance\n",
    "\n",
    "ad_syn_avg = ad_syn['distance'].mean()\n",
    "ad_ant_avg = ad_ant['distance'].mean()\n",
    "\n",
    "noun_syn_avg = noun_syn['distance'].mean()\n",
    "noun_ant_avg = noun_ant['distance'].mean()\n",
    "\n",
    "verb_syn_avg = verb_syn['distance'].mean()\n",
    "verb_ant_avg = verb_ant['distance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonym :  0.682\n",
      "antonym :  0.65\n"
     ]
    }
   ],
   "source": [
    "print(\"synonym : \", ((ad_syn_avg + noun_syn_avg + verb_syn_avg) / 3).round(3))\n",
    "print(\"antonym : \", ((ad_ant_avg + noun_ant_avg + verb_ant_avg) / 3).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_syn_avg :  0.64\n",
      "ad_ant_avg :  0.658\n",
      "noun_syn_avg :  0.683\n",
      "noun_ant_avg :  0.589\n",
      "verb_syn_avg :  0.723\n",
      "verb_ant_avg :  0.703\n"
     ]
    }
   ],
   "source": [
    "print(\"ad_syn_avg : \", ad_syn_avg.round(3))\n",
    "print(\"ad_ant_avg : \", ad_ant_avg.round(3))\n",
    "print(\"noun_syn_avg : \", noun_syn_avg.round(3))\n",
    "print(\"noun_ant_avg : \", noun_ant_avg.round(3))\n",
    "print(\"verb_syn_avg : \", verb_syn_avg.round(3))\n",
    "print(\"verb_ant_avg : \", verb_ant_avg.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
